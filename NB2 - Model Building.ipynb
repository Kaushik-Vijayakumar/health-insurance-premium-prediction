{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insurance Premium Price Predictor - Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import logging\n",
    "import pickle\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "import optuna\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating MLFlow Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///Users/kvijayakumar/Documents/GitHub/health-insurance-premium-prediction/mlruns/481284435214831350', creation_time=1731178692714, experiment_id='481284435214831350', last_update_time=1731178692714, lifecycle_stage='active', name='Insurance Premium Prediction', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Insurance Premium Prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('insurance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>BloodPressureProblems</th>\n",
       "      <th>AnyTransplants</th>\n",
       "      <th>AnyChronicDiseases</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>KnownAllergies</th>\n",
       "      <th>HistoryOfCancerInFamily</th>\n",
       "      <th>NumberOfMajorSurgeries</th>\n",
       "      <th>PremiumPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>183</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>28000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>166</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Diabetes  BloodPressureProblems  AnyTransplants  AnyChronicDiseases  \\\n",
       "0   45         0                      0               0                   0   \n",
       "1   60         1                      0               0                   0   \n",
       "2   36         1                      1               0                   0   \n",
       "3   52         1                      1               0                   1   \n",
       "4   38         0                      0               0                   1   \n",
       "\n",
       "   Height  Weight  KnownAllergies  HistoryOfCancerInFamily  \\\n",
       "0     155      57               0                        0   \n",
       "1     180      73               0                        0   \n",
       "2     158      59               0                        0   \n",
       "3     183      93               0                        0   \n",
       "4     166      88               0                        0   \n",
       "\n",
       "   NumberOfMajorSurgeries  PremiumPrice  \n",
       "0                       0         25000  \n",
       "1                       0         29000  \n",
       "2                       1         23000  \n",
       "3                       2         28000  \n",
       "4                       1         23000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Feature Target split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the data\n",
    "X = df.drop(columns=['PremiumPrice'])\n",
    "y = df['PremiumPrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standardizing for linear regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>BloodPressureProblems</th>\n",
       "      <th>AnyTransplants</th>\n",
       "      <th>AnyChronicDiseases</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>KnownAllergies</th>\n",
       "      <th>HistoryOfCancerInFamily</th>\n",
       "      <th>NumberOfMajorSurgeries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.233197</td>\n",
       "      <td>-0.850750</td>\n",
       "      <td>-0.938978</td>\n",
       "      <td>-0.243056</td>\n",
       "      <td>-0.469358</td>\n",
       "      <td>-1.306105</td>\n",
       "      <td>-1.399250</td>\n",
       "      <td>-0.523356</td>\n",
       "      <td>-0.365148</td>\n",
       "      <td>-0.891187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.307981</td>\n",
       "      <td>1.175433</td>\n",
       "      <td>-0.938978</td>\n",
       "      <td>-0.243056</td>\n",
       "      <td>-0.469358</td>\n",
       "      <td>1.170852</td>\n",
       "      <td>-0.277062</td>\n",
       "      <td>-0.523356</td>\n",
       "      <td>-0.365148</td>\n",
       "      <td>-0.891187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.411674</td>\n",
       "      <td>1.175433</td>\n",
       "      <td>1.064988</td>\n",
       "      <td>-0.243056</td>\n",
       "      <td>-0.469358</td>\n",
       "      <td>-1.008870</td>\n",
       "      <td>-1.258976</td>\n",
       "      <td>-0.523356</td>\n",
       "      <td>-0.365148</td>\n",
       "      <td>0.444239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.734763</td>\n",
       "      <td>1.175433</td>\n",
       "      <td>1.064988</td>\n",
       "      <td>-0.243056</td>\n",
       "      <td>2.130569</td>\n",
       "      <td>1.468086</td>\n",
       "      <td>1.125674</td>\n",
       "      <td>-0.523356</td>\n",
       "      <td>-0.365148</td>\n",
       "      <td>1.779665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.268369</td>\n",
       "      <td>-0.850750</td>\n",
       "      <td>-0.938978</td>\n",
       "      <td>-0.243056</td>\n",
       "      <td>2.130569</td>\n",
       "      <td>-0.216244</td>\n",
       "      <td>0.774990</td>\n",
       "      <td>-0.523356</td>\n",
       "      <td>-0.365148</td>\n",
       "      <td>0.444239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  Diabetes  BloodPressureProblems  AnyTransplants  \\\n",
       "0  0.233197 -0.850750              -0.938978       -0.243056   \n",
       "1  1.307981  1.175433              -0.938978       -0.243056   \n",
       "2 -0.411674  1.175433               1.064988       -0.243056   \n",
       "3  0.734763  1.175433               1.064988       -0.243056   \n",
       "4 -0.268369 -0.850750              -0.938978       -0.243056   \n",
       "\n",
       "   AnyChronicDiseases    Height    Weight  KnownAllergies  \\\n",
       "0           -0.469358 -1.306105 -1.399250       -0.523356   \n",
       "1           -0.469358  1.170852 -0.277062       -0.523356   \n",
       "2           -0.469358 -1.008870 -1.258976       -0.523356   \n",
       "3            2.130569  1.468086  1.125674       -0.523356   \n",
       "4            2.130569 -0.216244  0.774990       -0.523356   \n",
       "\n",
       "   HistoryOfCancerInFamily  NumberOfMajorSurgeries  \n",
       "0                -0.365148               -0.891187  \n",
       "1                -0.365148               -0.891187  \n",
       "2                -0.365148                0.444239  \n",
       "3                -0.365148                1.779665  \n",
       "4                -0.365148                0.444239  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "X_scaled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model building (Linear Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_train, X_scaled_test, y_train, y_test = train_test_split(X_scaled_df, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline model train metrics\n",
      "{'train_r2': 0.6219256563245064, 'train_mae': 2692.4716871413643, 'train_rmse': 3793.4572240024972, 'train_mape': 11.678689538341121}\n",
      "Baseline model test metrics\n",
      "{'test_r2': 0.7133944270278743, 'test_mae': 2586.2253840681055, 'test_rmse': 3495.9493282738235, 'test_mape': 10.962596602494685}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/10 04:10:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"LinearRegression\"):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_scaled_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_scaled_train)\n",
    "    train_metrics = {\n",
    "        'train_r2': r2_score(y_train, y_pred),\n",
    "        'train_mae': mean_absolute_error(y_train, y_pred),\n",
    "        'train_rmse': np.sqrt(mean_squared_error(y_train, y_pred)),\n",
    "        'train_mape': np.mean(np.abs((y_train - y_pred) / y_train)) * 100\n",
    "    }\n",
    "\n",
    "    print(\"Baseline model train metrics\")\n",
    "    print(train_metrics)\n",
    "\n",
    "    y_pred = model.predict(X_scaled_test)\n",
    "    test_metrics = {\n",
    "        'test_r2': r2_score(y_test, y_pred),\n",
    "        'test_mae': mean_absolute_error(y_test, y_pred),\n",
    "        'test_rmse': np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "        'test_mape': np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "    }\n",
    "\n",
    "    print(\"Baseline model test metrics\")\n",
    "    print(test_metrics)\n",
    "\n",
    "    with open(\"LinearRegression_model.pkl\", \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "    \n",
    "    mlflow.log_metrics(train_metrics)\n",
    "    mlflow.log_metrics(test_metrics)\n",
    "    mlflow.log_artifact(\"LinearRegression_model.pkl\")\n",
    "    mlflow.sklearn.log_model(model, \"LinearRegression\")\n",
    "    mlflow.set_tag(\"model_type\", \"LinearRegression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree based models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating methods for hyperparameter tuning with kfold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "def cross_validate_metrics(model, X, y, n_splits=5):\n",
    "    # Set up KFold cross-validation\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize metric lists\n",
    "    r2_scores, mae_scores, rmse_scores, mape_scores = [], [], [], []\n",
    "\n",
    "    # Cross-validate and collect metrics\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "        # Append metrics\n",
    "        r2_scores.append(r2_score(y_val, y_pred))\n",
    "        mae_scores.append(mean_absolute_error(y_val, y_pred))\n",
    "        rmse_scores.append(np.sqrt(mean_squared_error(y_val, y_pred)))\n",
    "        mape_scores.append(np.mean(np.abs((y_val - y_pred) / y_val)) * 100)\n",
    "\n",
    "    # Compute average scores across folds\n",
    "    avg_metrics = {\n",
    "        'r2': np.mean(r2_scores),\n",
    "        'mae': np.mean(mae_scores),\n",
    "        'rmse': np.mean(rmse_scores),\n",
    "        'mape': np.mean(mape_scores)\n",
    "    }\n",
    "\n",
    "    return avg_metrics\n",
    "\n",
    "def get_optuna_model(trial, model_name):\n",
    "    if model_name == 'LGBM': \n",
    "        model = {\n",
    "            \"model_class\" : lgb.LGBMRegressor,\n",
    "            \"params\" :{\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "                'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "                'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),\n",
    "                'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "                'verbosity': -1\n",
    "            }\n",
    "        }\n",
    "    elif model_name == 'XGBoost': \n",
    "        model = {\n",
    "            \"model_class\" : xgb.XGBRegressor,\n",
    "            \"params\" :{\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "                'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "                'min_child_weight': trial.suggest_int('min_child_weight', 1, 10)\n",
    "            }\n",
    "        }\n",
    "    elif model_name == 'GradientBoosting': \n",
    "        model = {\n",
    "            \"model_class\" : GradientBoostingRegressor,\n",
    "            \"params\" :{\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "                'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "                'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "                'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "            }\n",
    "        }\n",
    "    elif model_name == 'RandomForest': \n",
    "        model = {\n",
    "            \"model_class\" : RandomForestRegressor,\n",
    "            \"params\" :{\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "                'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "                'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "                'max_features': trial.suggest_int('max_features', 2, 10)\n",
    "            }\n",
    "        }\n",
    "    elif model_name == 'DecisionTree': \n",
    "        model = {\n",
    "            \"model_class\" : DecisionTreeRegressor,\n",
    "            \"params\" :{\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "                'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "                'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "                'max_features': trial.suggest_int('max_features', 2, 10)\n",
    "            }\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model name.\")\n",
    "\n",
    "    model_class = model.get(\"model_class\", None)\n",
    "    model_params = model.get(\"params\", {})\n",
    "    if not model:\n",
    "        raise ValueError(\"Invalid model name.\")\n",
    "    \n",
    "    return model_class(**model_params)\n",
    "\n",
    "def objective(trial, model_name, X, y):\n",
    "    # Get the hyperparameters for the selected model\n",
    "    model = get_optuna_model(trial, model_name)\n",
    "    \n",
    "    metrics = cross_validate_metrics(model, X, y)\n",
    "    \n",
    "    # Log metrics for each trial\n",
    "    trial.set_user_attr('r2_score', metrics['r2'])\n",
    "    trial.set_user_attr('mae', metrics['mae'])\n",
    "    trial.set_user_attr('rmse', metrics['rmse'])\n",
    "    trial.set_user_attr('mape', metrics['mape'])\n",
    "\n",
    "    composite_score = 0.5 * (metrics['r2']) + 0.5 * (1 - (metrics['mape']/100))\n",
    "    \n",
    "    return composite_score # metrics['r2'], metrics['mae'], metrics['rmse'], metrics['mape']\n",
    "\n",
    "def get_best_params(X, y, model_name):\n",
    "    study = optuna.create_study(study_name=\"model_name\", direction=\"maximize\")\n",
    "    study.optimize(lambda trial: objective(trial, model_name, X, y), n_trials=50)\n",
    "    \n",
    "    best_params = {}\n",
    "    best_params = study.best_params\n",
    "    print(f\"Best params for {model_name}: {best_params}\")\n",
    "    return best_params\n",
    "\n",
    "def get_model(model_name, params):\n",
    "    models = {\n",
    "        'LGBM': lgb.LGBMRegressor,\n",
    "        'XGBoost': xgb.XGBRegressor,\n",
    "        'GradientBoosting': GradientBoostingRegressor,\n",
    "        'RandomForest': RandomForestRegressor,\n",
    "        'DecisionTree': DecisionTreeRegressor\n",
    "    }\n",
    "    model = models.get(model_name, None)\n",
    "    \n",
    "    if not model:\n",
    "        raise ValueError(\"Invalid model name.\")\n",
    "    \n",
    "    return model(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating method for running Tree Based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tree_based_models(prefix, X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model_names = [\"DecisionTree\", \"RandomForest\", \"GradientBoosting\", \"LGBM\", \"XGBoost\" ]\n",
    "\n",
    "    mlflow.set_experiment(\"Insurance Premium Prediction\")\n",
    "    for model_name in model_names:\n",
    "        with mlflow.start_run(run_name=f\"{prefix}_{model_name}\"):\n",
    "            # Get the best hyperparameters for the model\n",
    "            best_params = get_best_params(X_train, y_train, model_name)\n",
    "\n",
    "            # Initialize and train the model with the best parameters\n",
    "            model = get_model(model_name, best_params)\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Make predictions and calculate metrics\n",
    "            y_pred = model.predict(X_train)\n",
    "            train_metrics = {\n",
    "                'train_r2': r2_score(y_train, y_pred),\n",
    "                'train_mae': mean_absolute_error(y_train, y_pred),\n",
    "                'train_rmse': np.sqrt(mean_squared_error(y_train, y_pred)),\n",
    "                'train_mape': np.mean(np.abs((y_train - y_pred) / y_train)) * 100\n",
    "            }\n",
    "            print(f\"[{prefix}] {model_name} - train metrics\")\n",
    "            print(train_metrics)\n",
    "\n",
    "            \n",
    "            y_pred = model.predict(X_test)\n",
    "            test_metrics = {\n",
    "                'test_r2': r2_score(y_test, y_pred),\n",
    "                'test_mae': mean_absolute_error(y_test, y_pred),\n",
    "                'test_rmse': np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "                'test_mape': np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "            }\n",
    "\n",
    "            print(f\"[{prefix}] {model_name} - test metrics\")\n",
    "            print(test_metrics)\n",
    "\n",
    "            with open(f\"{prefix}_{model_name}_model.pkl\", \"wb\") as f:\n",
    "                pickle.dump(model, f)\n",
    "            \n",
    "            mlflow.log_params(best_params)\n",
    "            mlflow.log_metrics(train_metrics)\n",
    "            mlflow.log_metrics(test_metrics)\n",
    "            mlflow.log_artifact(f\"{prefix}_{model_name}_model.pkl\")\n",
    "            mlflow.sklearn.log_model(model, f\"{prefix}_{model_name}\")\n",
    "            mlflow.set_tag(\"model_type\", model_name)\n",
    "            mlflow.set_tag(\"run_group\", prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for DecisionTree: {'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 7, 'max_features': 9}\n",
      "[default] DecisionTree - train metrics\n",
      "{'train_r2': 0.8179458968384365, 'train_mae': 1051.5992650891128, 'train_rmse': 2632.3693384490443, 'train_mape': 4.391990884912596}\n",
      "[default] DecisionTree - test metrics\n",
      "{'test_r2': 0.8459281893505853, 'test_mae': 1166.663981360951, 'test_rmse': 2563.211287729534, 'test_mape': 5.084894369835274}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/10 04:10:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for RandomForest: {'n_estimators': 175, 'max_depth': 11, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 10}\n",
      "[default] RandomForest - train metrics\n",
      "{'train_r2': 0.8652752221939994, 'train_mae': 909.9000368414287, 'train_rmse': 2264.4895754923145, 'train_mape': 3.783686995189781}\n",
      "[default] RandomForest - test metrics\n",
      "{'test_r2': 0.9022753511900503, 'test_mae': 1011.0261519734901, 'test_rmse': 2041.3847821230574, 'test_mape': 4.263238286942843}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/10 04:10:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for GradientBoosting: {'n_estimators': 272, 'max_depth': 11, 'learning_rate': 0.02350188013850998, 'subsample': 0.5816938372950098, 'min_samples_split': 7, 'min_samples_leaf': 2}\n",
      "[default] GradientBoosting - train metrics\n",
      "{'train_r2': 0.9841451657926266, 'train_mae': 364.6771266452088, 'train_rmse': 776.8325958627984, 'train_mape': 1.5604570013972394}\n",
      "[default] GradientBoosting - test metrics\n",
      "{'test_r2': 0.8610772114514513, 'test_mae': 1158.9576078838654, 'test_rmse': 2433.938272405857, 'test_mape': 5.223965113241789}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/10 04:11:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for LGBM: {'n_estimators': 106, 'max_depth': 10, 'learning_rate': 0.04268247632667656, 'num_leaves': 40, 'min_child_samples': 14, 'subsample': 0.73036154347567, 'colsample_bytree': 0.9861107133062623}\n",
      "[default] LGBM - train metrics\n",
      "{'train_r2': 0.8852935723876754, 'train_mae': 981.7204709110479, 'train_rmse': 2089.4908080549485, 'train_mape': 4.131832376164083}\n",
      "[default] LGBM - test metrics\n",
      "{'test_r2': 0.8867218714412956, 'test_mae': 1259.4469318269655, 'test_rmse': 2197.838852945361, 'test_mape': 5.534589732143662}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/10 04:12:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for XGBoost: {'n_estimators': 241, 'max_depth': 6, 'learning_rate': 0.01632470690511597, 'subsample': 0.9915756496704171, 'colsample_bytree': 0.924673751945451, 'min_child_weight': 3}\n",
      "[default] XGBoost - train metrics\n",
      "{'train_r2': 0.9278416542307883, 'train_mae': 824.8750322216054, 'train_rmse': 1657.2570377447817, 'train_mape': 3.480686124288583}\n",
      "[default] XGBoost - test metrics\n",
      "{'test_r2': 0.8697337527187889, 'test_mae': 1285.904725970644, 'test_rmse': 2356.8870208515846, 'test_mape': 5.5069180958171335}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/10 04:13:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "run_tree_based_models(\"default\", X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for DecisionTree: {'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_features': 9}\n",
      "[with_bmi] DecisionTree - train metrics\n",
      "{'train_r2': 0.7854681282158249, 'train_mae': 1404.6058410783014, 'train_rmse': 2857.5411867261173, 'train_mape': 5.639641605119436}\n",
      "[with_bmi] DecisionTree - test metrics\n",
      "{'test_r2': 0.8442763223986237, 'test_mae': 1495.7980017285763, 'test_rmse': 2576.915272888893, 'test_mape': 6.0124797966378365}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/10 04:13:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for RandomForest: {'n_estimators': 186, 'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': 10}\n",
      "[with_bmi] RandomForest - train metrics\n",
      "{'train_r2': 0.8879904327502072, 'train_mae': 813.5583155532626, 'train_rmse': 2064.781723720136, 'train_mape': 3.413230747147817}\n",
      "[with_bmi] RandomForest - test metrics\n",
      "{'test_r2': 0.9051412336602691, 'test_mae': 1018.3989054677121, 'test_rmse': 2011.2291266521247, 'test_mape': 4.319470183675798}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/10 04:14:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for GradientBoosting: {'n_estimators': 59, 'max_depth': 6, 'learning_rate': 0.06424689100649494, 'subsample': 0.7594079907899678, 'min_samples_split': 4, 'min_samples_leaf': 6}\n",
      "[with_bmi] GradientBoosting - train metrics\n",
      "{'train_r2': 0.9024455015837329, 'train_mae': 962.8788383211269, 'train_rmse': 1926.9490774145359, 'train_mape': 4.045105996896055}\n",
      "[with_bmi] GradientBoosting - test metrics\n",
      "{'test_r2': 0.8881519706768974, 'test_mae': 1281.530441689677, 'test_rmse': 2183.921289770741, 'test_mape': 5.534822306522713}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/10 04:14:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for LGBM: {'n_estimators': 69, 'max_depth': 6, 'learning_rate': 0.038079687387325985, 'num_leaves': 57, 'min_child_samples': 13, 'subsample': 0.5575427431228935, 'colsample_bytree': 0.9786441286427869}\n",
      "[with_bmi] LGBM - train metrics\n",
      "{'train_r2': 0.8339462366283389, 'train_mae': 1313.8417874356312, 'train_rmse': 2514.032855493517, 'train_mape': 5.571798397898335}\n",
      "[with_bmi] LGBM - test metrics\n",
      "{'test_r2': 0.8731820610717311, 'test_mae': 1426.9553478361247, 'test_rmse': 2325.482946563472, 'test_mape': 6.186946752002692}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/10 04:15:49 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for XGBoost: {'n_estimators': 224, 'max_depth': 6, 'learning_rate': 0.021670020166891565, 'subsample': 0.9992611691193074, 'colsample_bytree': 0.960684765723908, 'min_child_weight': 3}\n",
      "[with_bmi] XGBoost - train metrics\n",
      "{'train_r2': 0.9463980893978119, 'train_mae': 691.15502186112, 'train_rmse': 1428.3568530175492, 'train_mape': 2.892290379488785}\n",
      "[with_bmi] XGBoost - test metrics\n",
      "{'test_r2': 0.868020749310808, 'test_mae': 1280.9885722458964, 'test_rmse': 2372.3329606766533, 'test_mape': 5.579906790740438}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/10 04:17:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "X_BMI = X.copy(deep=True)\n",
    "X_BMI['BMI'] = X_BMI['Weight'] / ((X_BMI['Height']/100)**2)\n",
    "run_tree_based_models(\"with_bmi\", X_BMI, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for Final: {'n_estimators': 150, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_features': 11}\n",
      "[Final] RandomForest - train metrics\n",
      "{'train_r2': 0.8843072488114224, 'train_mae': 823.8924834491502, 'train_rmse': 2098.4550080169474, 'train_mape': 3.4342817305872444}\n",
      "[Final] RandomForest - test metrics\n",
      "{'test_r2': 0.901754278444125, 'test_mae': 995.7627579427259, 'test_rmse': 2046.8199298354173, 'test_mape': 4.2613816033328105}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/10 04:24:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "def random_forest_objective(trial, X, y):\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators = trial.suggest_int('n_estimators', 135, 165),\n",
    "        max_depth = trial.suggest_int('max_depth', 8, 12),\n",
    "        min_samples_split = trial.suggest_int('min_samples_split', 5, 9),\n",
    "        min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 3),\n",
    "        max_features = trial.suggest_int('max_features', 7, 11)\n",
    "    )\n",
    "\n",
    "    metrics = cross_validate_metrics(model, X, y)\n",
    "    \n",
    "    # Log metrics for each trial\n",
    "    trial.set_user_attr('r2_score', metrics['r2'])\n",
    "    trial.set_user_attr('mae', metrics['mae'])\n",
    "    trial.set_user_attr('rmse', metrics['rmse'])\n",
    "    trial.set_user_attr('mape', metrics['mape'])\n",
    "\n",
    "    composite_score = 0.5 * (metrics['r2']) + 0.5 * (1 - (metrics['mape']/100))\n",
    "    \n",
    "    return composite_score # metrics['r2'], metrics['mae'], metrics['rmse'], metrics['mape']\n",
    "\n",
    "with mlflow.start_run(run_name=\"Final\"):\n",
    "    X_BMI_train, X_BMI_test, y_train, y_test = train_test_split(X_BMI, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "    study = optuna.create_study(study_name=\"final\", direction=\"maximize\")\n",
    "    study.optimize(lambda trial: random_forest_objective(trial, X_BMI_train, y_train), n_trials=200)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    print(f\"Best params for Final: {best_params}\")\n",
    "    model = RandomForestRegressor(**best_params)\n",
    "    model.fit(X_BMI_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_BMI_train)\n",
    "    train_metrics = {\n",
    "        'train_r2': r2_score(y_train, y_pred),\n",
    "        'train_mae': mean_absolute_error(y_train, y_pred),\n",
    "        'train_rmse': np.sqrt(mean_squared_error(y_train, y_pred)),\n",
    "        'train_mape': np.mean(np.abs((y_train - y_pred) / y_train)) * 100\n",
    "    }\n",
    "\n",
    "    y_pred = model.predict(X_BMI_test)\n",
    "    test_metrics = {\n",
    "        'test_r2': r2_score(y_test, y_pred),\n",
    "        'test_mae': mean_absolute_error(y_test, y_pred),\n",
    "        'test_rmse': np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "        'test_mape': np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "    }\n",
    "\n",
    "    print(f\"[Final] RandomForest - train metrics\")\n",
    "    print(train_metrics)\n",
    "\n",
    "    print(f\"[Final] RandomForest - test metrics\")\n",
    "    print(test_metrics)\n",
    "\n",
    "    with open(\"Final_RandomForest_model.pkl\", \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.log_metrics(train_metrics)\n",
    "    mlflow.log_metrics(test_metrics)\n",
    "    mlflow.log_artifact(\"Final_RandomForest_model.pkl\")\n",
    "    mlflow.sklearn.log_model(model, \"Final_RandomForest\")\n",
    "    mlflow.set_tag(\"model_type\", \"RandomForest\")\n",
    "    mlflow.set_tag(\"run_group\", \"Final\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
